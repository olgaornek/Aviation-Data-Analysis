## Average Departure Delay time by Airline
%sql
SELECT airline, 
       COUNT(*) AS total_flights,
       ROUND(AVG(COALESCE((CAST(departure_actual AS INT) - CAST(departure_scheduled AS INT)) / 60, 0)), 0) AS avg_departure_delay_minutes
FROM temp_view_ss
GROUP BY airline
ORDER BY total_flights DESC

## Current Flight Status
from pyspark.sql.functions import col, when

df_spark = df_spark.withColumn(
    "flight_status",
    when(col("arrival_actual").isNull() & (col("departure_actual").isNull()), "scheduled")
    .when(col("arrival_actual").isNull() & (col("departure_actual").isNotNull()), "active")
    .when(col("arrival_actual").isNotNull(), "landed")
)

flight_status_count = df_spark.groupBy("flight_status").count()
display(flight_status_count)

## Busiest Route
### ðŸš€ Combined count + display + chart in one go

from pyspark.sql.functions import col, coalesce, lit, desc

### 1. Compute departures and arrivals
departure_counts = (
    df_spark
      .filter(col("departure_airport").isNotNull())
      .groupBy("departure_airport")
      .count()
      .withColumnRenamed("departure_airport", "airport")
      .withColumnRenamed("count", "departure_count")
)
arrival_counts = (
    df_spark
      .filter(col("arrival_airport").isNotNull())
      .groupBy("arrival_airport")
      .count()
      .withColumnRenamed("arrival_airport", "airport")
      .withColumnRenamed("count", "arrival_count")
)

### 2. Join & totalize
airport_counts = (
    departure_counts
      .join(arrival_counts, on="airport", how="full_outer")
      .select(
          "airport",
          coalesce(col("departure_count"), lit(0)).alias("departure_count"),
          coalesce(col("arrival_count")   , lit(0)).alias("arrival_count")
      )
      .withColumn("total_flights", col("departure_count") + col("arrival_count"))
      .orderBy(desc("total_flights"))
      .limit(10)
)

### 3. Show tables
print("=== Flight frequency per airport ===")
display(airport_counts)

print("=== Busiest airport ===")
display(airport_counts.limit(1))

# Flight Frequency Per Route or Region
result = (
    df_spark
      .groupBy(
          col("departure_airport").alias("starting_location"),
          col("arrival_airport").alias("destination")
      )
      .count()
      .orderBy(desc("count"))
      .limit(10)
)

display(result)

#### Convert to Pandas for plotting
pdf_result = result.toPandas()

##### Plot the top 10 routes in descending order
plt.figure(figsize=(12, 8))
plt.barh(pdf_result['starting_location'] + " -> " + pdf_result['destination'], pdf_result['count'])
plt.xlabel('Number of Flights')
plt.ylabel('Route')
plt.title('Top 10 Busiest Flight Routes')
plt.gca().invert_yaxis()  # Invert y-axis to show data in descending order
plt.tight_layout()
plt.show()

# Active Flight Punctuality by Airport & Direction
from pyspark.sql.functions import when, col

#### Helper function to compute punctuality
def compute_punctuality(actual_col, scheduled_col):
    return when(col(actual_col).isNull(), None) \
           .when(col(actual_col) > col(scheduled_col), "Late") \
           .when(col(actual_col) < col(scheduled_col), "Early") \
           .otherwise("On-Time")

#### Convert pandas DataFrame to Spark DataFrame
df_spark = spark.createDataFrame(df)

#### Add departure and arrival punctuality columns
df_spark = df_spark \
    .withColumn("departure_punctuality", compute_punctuality("departure_actual", "departure_scheduled")) \
    .withColumn("arrival_punctuality", compute_punctuality("arrival_actual", "arrival_scheduled"))

#### Check schema and columns
df_spark.printSchema()
print("Columns:", df_spark.columns)

#### Recreate the temp view
df_spark.createOrReplaceTempView("temp_view")

#### Show via DataFrame API
display(df_spark)


from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit

spark = SparkSession.builder.getOrCreate()

#### 1) Compute departure counts
dep_counts = spark.sql("""
  SELECT
    departure_airport   AS airport,
    departure_punctuality AS punctuality,
    flight_status,
    COUNT(*) AS count_punctuality
  FROM temp_view
  WHERE flight_status = 'active'
  GROUP BY departure_airport, departure_punctuality, flight_status
""").withColumn("direction", lit("departure"))

#### # 2) Compute arrival counts
arr_counts = spark.sql("""
  SELECT
    arrival_airport     AS airport,
    arrival_punctuality   AS punctuality,
    flight_status,
    COUNT(*) AS count_punctuality
  FROM temp_view
  WHERE flight_status = 'landed'
  GROUP BY arrival_airport, arrival_punctuality, flight_status
""").withColumn("direction", lit("arrival"))

#### 3) Union into one DataFrame
combined = dep_counts.unionByName(arr_counts)

#### 4) Register / inspect
combined.createOrReplaceTempView("punctuality_summary")
combined.printSchema()
print("Columns:", combined.columns)
display(combined)

#### â€”â€” Optional: pivot & plot with pandas + matplotlib â€”â€” #

#### Convert to Pandas (only if small enough)
pdf = combined.toPandas()

import matplotlib.pyplot as plt

#### Pivot so each punctuality category becomes a column
pivoted = pdf.pivot_table(
    index=["airport","direction"],
    columns="punctuality",
    values="count_punctuality",
    fill_value=0
)

#### Make a stacked bar chart
pivoted.plot(
    kind="bar",
    stacked=True,
    figsize=(10,6)
)
plt.ylabel("Number of Active Flights")
plt.title("Active Flight Punctuality by Airport & Direction")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

